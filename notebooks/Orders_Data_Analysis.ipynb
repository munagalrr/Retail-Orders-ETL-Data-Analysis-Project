{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a7b7b0a-8030-4127-8009-f15bee98d818",
   "metadata": {},
   "source": [
    "# ETL project using Retail Orders dataset \n",
    "<li><p> <b>Extracted</b> data from Kaggle API</p></li>\n",
    "<li><p> Data cleaning and <b>Transformation</b> using Python(Pandas module)</p></li>\n",
    "<li><p> <b>Loaded</b> data to the SQL Server</p></li>\n",
    "<li><p> Perfomed data analysis using SQL Server</p></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "428c0884-2379-4188-81e9-2e2259af6c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/ankitbansal06/retail-orders\n",
      "License(s): CC0-1.0\n",
      "404 Client Error: Not Found for url: https://www.kaggle.com/api/v1/datasets/download/ankitbansal06/retail-orders/orders.csv;?filename=orders.csv%3B&raw=false\n"
     ]
    }
   ],
   "source": [
    "#Import libraries/Modules\n",
    "#!pip install kaggle\n",
    "import kaggle\n",
    "!kaggle datasets download ankitbansal06/retail-orders -f orders.csv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73428d40-3204-4e8d-adae-9b3a5f749869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract file from zipfile\n",
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('orders.csv.zip')\n",
    "zip_ref.extractall() #extract file to dir\n",
    "zip_ref.close() #close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "516903aa-111c-439f-bd0f-b6e957569b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas module/library and load data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('orders.csv', na_values=['Not Available','unknown'])\n",
    "df.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "16e315cd-4d4e-4d7f-97da-df8e58c7bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for data types, data format, missing data, wrong data types, anomaly data\n",
    "df.describe()\n",
    "df.dtypes\n",
    "df.info()\n",
    "df['Ship Mode'].unique();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "76bd96e7-62bc-435b-b3a2-e75ea6260900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns make them lower case and replace space with underscore\n",
    "#df.rename(columns={'Order Id': 'order_id', 'Order Date': 'order_date'}) # one method and need to apply all coloumns manually\n",
    "df.columns=df.columns.str.lower() # alternative and efficient method where all column names changes once.\n",
    "df.columns = df.columns.str.replace(' ', '_') # And then replace the space between strings with underscore\n",
    "df.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5113645e-e9eb-4fac-a30c-39517b339b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#derive new columns discount, sale price and profit\n",
    "df['discount'] = df['list_price']*df['discount_percent']*0.01\n",
    "df['sale_price'] = df['list_price']- df['discount']\n",
    "df['profit_per_item'] = df['sale_price'] - df['cost_price']\n",
    "#df['total_order_value'] = df['sale_price']*df['quantity']\n",
    "#df['order_total_profit'] = df['profit/item']*df['quantity']\n",
    "df.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c849daa7-b740-49d4-8e4c-84e6985c2610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert order date from object data type to date\n",
    "df['order_date']=pd.to_datetime(df['order_date'], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a035e37b-0621-4f94-9c4b-7b3211b0b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop cost price, list price and discount percent columns\n",
    "df.drop(columns=['cost_price','list_price','discount_percent'], inplace=True)\n",
    "df.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "410810f3-9518-4bdd-a52d-091414425023",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful: 1\n"
     ]
    }
   ],
   "source": [
    "#load the data intp sql server\n",
    "import sqlalchemy as sal\n",
    "from sqlalchemy import text\n",
    "##using window authentication\n",
    "#engine = sal.create_engine('mssql://Legion/master?driver=ODBC+DRIVER+17+FOR+SQL+SERVER')\n",
    "#conn = engine.connect()\n",
    "# Database credentials\n",
    "#using sql server authentication connection\n",
    "username = 'userName'\n",
    "password = 'password'\n",
    "server = 'serverName'  # e.g., 'localhost', 'SERVER\\INSTANCE'\n",
    "database = 'master'\n",
    "driver = 'ODBC Driver 17 for SQL Server' # or another appropriate driver like 'SQL Server' or 'SQL Server Native Client 11.0'\n",
    "\n",
    "# Construct the connection string\n",
    "connection_string = (\n",
    "    f'mssql+pyodbc://{username}:{password}@{server}/{database}?'\n",
    "    f'driver={driver}'\n",
    ")\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = sal.create_engine(connection_string)\n",
    "\n",
    "# Example usage (optional)\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(\"Test Query\"))\n",
    "        print(\"Connection successful:\", result.scalar())\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to the database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "48c49bf0-6e06-4029-81cf-58ce0d4efcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Load data to the existing data table in SQL Server\n",
    "#df.to_sql('df_orders', con=engine.connect(), index=False, if_exists='replace') # replace will create a table and add data to the database\n",
    "# Create table in database is the most efficient way while pandas will create a table with highest possible data types eg. varchar(max), bigint.  and it will consume more memory space.\n",
    "df.to_sql('df_orders', con=engine.connect(), index=False, if_exists='append') # append will add/append the data to the existing table in the database"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
